{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow basic\n",
    "----------------------------\n",
    "[Getting Started With TensorFlow](https://www.tensorflow.org/get_started/get_started)  \n",
    "You might think of TensorFlow Core programs as consisting of two discrete sections:\n",
    "1. Building the computational graph.\n",
    "2. Running the computational graph.\n",
    "A **computational graph** is a series of TensorFlow operations arranged into a graph of nodes.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.graph visualization util function\n",
    "# code from 'https://stackoverflow.com/questions/38189119/simple-way-to-visualize-a-tensorflow-graph-in-jupyter'\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add()\n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two constants.\n",
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that printing the **nodes does not output the values 3.0 and 4.0** as you might expect. Instead, they are nodes that, when evaluated, would produce 3.0 and 4.0, respectively. To actually evaluate the nodes, we must run **the computational graph within a session.** A session encapsulates the control and state of the TensorFlow runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "ret1, ret2 = sess.run([node1, node2])\n",
    "print(ret1, ret2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can build more complicated computations by combining **Tensor** nodes with operations (Operations are also nodes.). For example, we can add our two constant nodes and produce a new graph as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "node3 = tf.add(node1, node2)\n",
    "print(\"node3: \", node3)\n",
    "print(\"sess.run(node3): \", sess.run(node3))\n",
    "\n",
    "# Let's visualize these nodes\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it stands, this graph is not especially interesting because it always produces a constant result. A graph can be parameterized to accept external inputs, known as **placeholders**. A **placeholder** is a promise to provide a value later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2 = tf.Graph()\n",
    "with graph2.as_default():\n",
    "    a = tf.placeholder(tf.float32)\n",
    "    b = tf.placeholder(tf.float32)\n",
    "    adder_node = a + b  # + provides a shortcut for tf.add(a, b)\n",
    "    \n",
    "print(a)\n",
    "print(b)\n",
    "print(adder_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph2)\n",
    "print(tf.get_default_graph()) # default_graph\n",
    "print(a.graph) # graph2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's feed some values to graph\n",
    "sess2 = tf.Session(graph=graph2)\n",
    "print(sess2.run(adder_node, feed_dict={a: 3, b:4.5}))\n",
    "print(sess2.run(adder_node, feed_dict={a: [1,3], b: [2, 4]}))\n",
    "\n",
    "# Let's visualize these nodes\n",
    "show_graph(graph2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning we will typically want a model that can take arbitrary inputs, such as the one above. To make the model trainable, we need to be able to modify the graph to get new outputs with the same input. **Variables** allow us to add **trainable parameters** to a graph. They are constructed with a type and initial value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close(), sess2.close() # close session\n",
    "tf.reset_default_graph() # reset our default graph\n",
    "sess = tf.Session() # We need to renew Session because the first graph is not valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable([.3], tf.float32, name='weight')\n",
    "b = tf.Variable([-.3], tf.float32, name='bias')\n",
    "x = tf.placeholder(tf.float32, name='input')\n",
    "linear_model = W * x + b\n",
    "\n",
    "print(W)\n",
    "print(b)\n",
    "print(x)\n",
    "print(linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are **not initialized** when you call **tf.Variable**. To initialize all the variables in a TensorFlow program, you must explicitly call a special operation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can use tf.global_variables_initializer().run() instead\n",
    "# when using tf.InteractiveSession()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(linear_model, {x:[1,2,3,4]}))\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run([W, b]))\n",
    "\n",
    "# Simple linear regression\n",
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "for i in range(1000):\n",
    "  sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})\n",
    "\n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow.Saver\n",
    "------------------------\n",
    "[Tensorflow saver tutorial](https://www.tensorflow.org/programmers_guide/variables)   \n",
    "[Hello, TensorFlow!](https://www.oreilly.com/learning/hello-tensorflow)\n",
    "\n",
    "We can use **tf.Saver** to save our variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'ckpt_linear'\n",
    "MODEL_PATH = os.path.join(PATH, 'linear')\n",
    "if not os.path.exists(PATH):\n",
    "    os.makedirs(PATH)\n",
    "saver.save(sess, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init)\n",
    "print(W.eval(sess), b.eval(sess)) # equivalent with sess.run([W, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess, MODEL_PATH)\n",
    "print(W.eval(sess), b.eval(sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can save our optimized variables. But, it does **not reconstruct our models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset graph\n",
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "W = tf.Variable([.3], tf.float32, name='weight')\n",
    "b = tf.Variable([-.3], tf.float32, name='bias')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, MODEL_PATH)\n",
    "show_graph(tf.get_default_graph()) # This model has only two variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to restore model from meta data of the latest saved graph. The method, tf.Saver.save(), automatically created meta data of the model with **'(my_model_name).meta'**. So, we can restore our model as following codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "saver = tf.train.import_meta_graph(MODEL_PATH + '.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint(PATH))\n",
    "\n",
    "# get the variable by name\n",
    "print(sess.run(['weight:0', 'bias:0']))\n",
    "\n",
    "# restore python object to feed new data\n",
    "graph = tf.get_default_graph()\n",
    "x = graph.get_tensor_by_name('input:0')\n",
    "linear_model = graph.get_tensor_by_name('add:0')\n",
    "\n",
    "print(sess.run(linear_model, feed_dict={x: [1, 2, 3, 4]}))\n",
    "show_graph(graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36-tensorflow-gpu",
   "language": "python",
   "name": "py36-tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
